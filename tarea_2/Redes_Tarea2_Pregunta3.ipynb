{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47UiWbvtPMez"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/MARCA-Color.jpg\" title=\"Title text\" width=\"50%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 2 - Redes Convolucionales y sus aplicaciones </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "\n",
    "\n",
    "**Temas**  \n",
    "* Diseño y entrenamiento de Redes Neuronales Convolucionales (CNNs).\n",
    "* Regularización en Redes Convolucionales.\n",
    "* *Transfer Learning.*\n",
    "* Aplicaciones de las Redes Neuronales Convolucionales\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* **Fecha de entrega y discusión: 23 de Noviembre**\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<margarita.bugueno.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<cvalle@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea2-INF395-II-2018] \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Convolutional Neural Networks (CNN) en CIFAR.  \n",
    "[2.](#segundo) Transfer Learning.   \n",
    "[3.](#tercero) Convolutional Neural Network sobre texto.\n",
    "\n",
    "\n",
    "### **Nota Importante:**  \n",
    "Para esta actividad **si es que no se cuenta con GPU** se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__* . Así, podrá programar en la nube con recursos elevados y luego descargar el Jupyter Notebook y entregarlo en modo Informe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5k7AJzX1-bdn"
   },
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Convolutional Neural Networks (CNN) en CIFAR \n",
    "\n",
    "En esta sección trabajaremos con un dataset bastante conocido y utilizado por la comunidad para experimentar reconocimiento de objetos en imágenes: CIFAR10 [3]. Se trata de un conjunto de 60.000 imágenes RGB de 32 × 32 pixeles que contiene 10 clases de objetos y 6000 ejemplos por clase. La versión utilizada se le atribuye a *A. Krizhevsky, V. Nair* y *G. Hinton* y viene separada en 50000 ejemplos de entrenamiento y 10000 casos de prueba que fueron obtenidos seleccionando 1000 imágenes aleatorias de cada clase.  \n",
    "Los datos restantes han sido ordenados aleatoriamente y están organizados en 5 bloques de entrenamiento o batches. Cabe destacar que las clases son mutuamente excluyentes y corresponden a las siguientes categorı́as: \n",
    "\n",
    "* Gato\n",
    "* Perro\n",
    "* Rana\n",
    "* Caballo\n",
    "* Pájaro\n",
    "* Ciervo\n",
    "* Avión\n",
    "* Automóvil\n",
    "* Camión \n",
    "* Barco\n",
    "\n",
    "Para esta tarea se experimentará con redes convolucionales, conocidas como CNNs ó ConvNets.  \n",
    "**Nota:** Para esta actividad es bastante aconsejable entrenar las redes usando una GPU, ya que de otro modo los tiempos de entrenamiento serán largos. Recuerde instalar Keras con gpu y el driver de cuda para la tarjeta gráfica.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU-6Yz50-iEw"
   },
   "source": [
    "> **a)** Construya una función que cargue todos los bloques de entrenamiento y pruebas del problema CIFAR generando como salida:  \n",
    "(i) dos matrices  Xtr, Ytr; correspondientes a las imágenes y etiquetas de entrenamiento  \n",
    "(ii) dos matrices Xt, Yt; correspondientes a las imágenes y etiquetas de pruebas  \n",
    "(iii) dos matrices Xv, Yv; correspondientes a las imágenes y etiquetas que se usarán como conjunto de validación (para tomar decisiones de diseño acerca del modelo)  \n",
    "\n",
    "> **Este último conjunto debe ser extraı́do desde el conjunto de entrenamiento original y no debe superar las 5000 imágenes.**\n",
    "\n",
    "> ```python\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  \n",
    "import numpy as np   \n",
    "import os   \n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3vyk2LS-kc7"
   },
   "source": [
    "> **b)** Prepare subconjuntos de entrenamiento, validación y pruebas normalizando las imágenes de entrenamiento y pruebas, dividiendo las intensidades originales de pixel en cada canal por 255.  Es importante notar que si desea trabajar con el orden de las dimensiones denominado ’tf’ (por defecto para TensorFlow) deberá realizar la transposición correspondiente para dejar el canal en donde corresponda. Finalmente, genere una representación adecuada de las salidas deseadas de la red.\n",
    "```python\n",
    "import keras\n",
    "x_train = x_train.transpose([0, 3, 1, 2]) #only if 'tf' dim-ordering is to be used\n",
    "x_test= x_test.transpose([0, 3, 1, 2]) #remove if 'th' dim-ordering is to be used\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTirGmLB-rDO"
   },
   "source": [
    "> **c)** Defina una CNN con arquitectura $C \\times P \\times C \\times P \\times F \\times F$. Para ambas capas convolucionales utilice 64 filtros de $3 \\times 3$ y funciones de activación ReLU. Para las capas de pooling utilice filtros de $2 \\times 2$ con stride 2. Para la capa MLP escondida use 512 neuronas. Genere un esquema lo más compacto posible que muestre los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un forward-pass y el número de parámetros de cada capa.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46K1jCVy-rIF"
   },
   "source": [
    "> **d)**  Entrene la CNN definida en **c)** utilizando SGD. En este dataset, una tasa de aprendizaje “segura” es $\\eta = 10^{-4}$ o inferior, pero durante las primeras *epochs* el entrenamiento resulta demasiado lento. Para resolver el problema aprenderemos a controlar la tasa de aprendizaje utilizada en el entrenamiento. Implemente la siguiente idea: deseamos partir con una tasa de aprendizaje $\\eta = 10^{-3}$ y dividir por 2 ese valor cada 10 epochs. Suponga además que no queremos usar una tasa de aprendizaje menor a $\\eta = 10^{-5}$.  Construya un gráfico que muestre los errores de entrenamiento, validación y pruebas como función del número de “epochs”, entrene con 25 *epochs*.\n",
    "```python\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    lrate = initial_lrate * math.pow(0.5, math.floor((1+epoch)/5))\n",
    "    lrate = max(lrate,0.00001)\n",
    "    return lrate\n",
    "opt = SGD(lr=0.0, momentum=0.9, decay=0.0)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.compile( ... )\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(x_val,y_val), shuffle=True, callbacks=[lrate])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPoWJQdc-rL3"
   },
   "source": [
    "> **e)** Entrene la CNN definida en c) utilizando **RMSProp** durante 25 *epochs*. Elija la función de pérdida más apropiada para este problema. Construya finalmente un gráfico que muestre los errores de entrenamiento, validación y pruebas como función del número de *epochs*.  \n",
    "*Hint: La curva sugiere algún cambio en el modelo definido, considere ésto en cuenta para las experimentaciones futuras.*\n",
    "```python\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile( ... )\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(x_val, y_val),shuffle=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnPP81S5-rPn"
   },
   "source": [
    "> **f)** Evalúe el efecto de modificar el tamaño de los filtros (de convolución) reportando la sensibilidad del error de pruebas a estos cambios en dos tipos de arquitecturas, una profunda y otra no. Presente un gráfico o tabla resumen. Por simplicidad entre durante sólo 15-20 *epochs*.\n",
    "```python\n",
    "\"\"\"Shallow network\"\"\"\n",
    "nc = #convolutional filter size\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (nc, nc), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrcSFrSI-rWD"
   },
   "source": [
    "> **g)** Se ha sugerido que la práctica bastante habitual de continuar una capa convolucional con una capa de *pooling* puede generar una reducción prematura de las dimensiones del patrón de entrada. Experimente con una arquitectura del tipo $C \\times P \\times C \\times P \\times F \\times F$ versus  $C \\times C \\times P \\times C \\times C \\times P \\times F \\times F$. Use 64 filtros para la primera capa convolucional y 128 para la segunda (o 64 filtros para las primeras 2 capas convolucionales y 128 para las dos últimas).  \n",
    "\n",
    "> Reflexione sobre qué le parece más sensato: ¿qué estructura permite un mejor desempeño y/o extracción de atributos de interés?¿es aconsejable mantener el tamaño de los filtros usados anteriormente (pregunta anterior)? o ¿usar filtros más grandes en la segunda capa convolucional y más pequeños en la primera? o ¿usar filtros más pequeños en la segunda capa convolucional y más grandes en la primera?  \n",
    "> **Hint:** con esta nueva arquitectura debiese superar el 70% de accuracy (de validación/test) antes de 5 epochs, pero la arquitectura es más sensible a overfitting por lo que podrı́a ser conveniente agregar un regularizador. Como resultado final de esta actividad gráfique los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuWtQ-5w_Gmc"
   },
   "source": [
    "> **h)** Algunos investigadores, han propuesto que las capas de *pooling* se pueden reemplazar por capas convoluciones con stride 2. ¿Se reduce dimensionalidad de este modo? Compruébelo verificando los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un *forward-pass*.  \n",
    "Entrene la red resultante con el método que prefiera, gráficando los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOHzsFkx_JsN"
   },
   "source": [
    "> **i)** Una forma interesante de regularizar modelos entrenados para visión artificial consiste en “aumentar” el número de ejemplos de entrenamiento usando transformaciones sencillas como: rotaciones, corrimientos y reflexiones, tanto horizontales como verticales. Explique por qué este procedimiento podrı́a ayudar a mejorar el modelo y el por qué las etiquetas no cambian al aplicar estas operaciones. Evalúe experimentalmente la conveniencia de incorporarlo.\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),steps_per_epoch=x_train.shape[0]// batch_size, epochs=epochs,validation_data=(x_test, y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHTcmtUjW5KH"
   },
   "source": [
    "> **j)** Para una comparación del desempeño de la red neuronal, pre-procese el dataset de CIFAR-10 y calcule los descriptores manuales SIFT, para un mejor entendimiento de éstos consulte:  https://ianlondon.github.io/blog/how-to-sift-opencv/ y https://docs.opencv.org/3.4.3/da/df5/tutorial_py_sift_intro.html. Como se genera un descriptor de 128 dimensiones para cada *keypoint* comprima esta información de alguna manera, comente sobre la operación.\n",
    "\n",
    "> Es necesario instalar *OpenCV* para realizar el cálculo de este descriptor.  \n",
    "```python\n",
    "!pip install opencv-python==3.1 opencv-contrib-python==3.4.2.16\n",
    "```\n",
    "  \n",
    "\n",
    ">```python\n",
    "import cv2\n",
    "def pre_process(img):\n",
    "    if np.max(img) <= 1:\n",
    "        img*=255\n",
    "    img = img.astype(\"uint8\")\n",
    "    img_gray= cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img_gray\n",
    "def calculate_sift(cifar):\n",
    "    sift_cifar = []\n",
    "    for image in cifar:\n",
    "      img_gray = pre_process(image)\n",
    "      sift = cv2.xfeatures2d.SIFT_create()\n",
    "      kp, desc = sift.detectAndCompute(img_gray, None)\n",
    "      if type(desc) == type(None):\n",
    "        desc = np.zeros((1,128))\n",
    "      compress_desc = np.mean(desc,axis=0) #compress all keypoints\n",
    "      sift_cifar.append(compress_desc)\n",
    "    return np.asarray(sift_cifar)\n",
    "cifar_sift = calculate_sift(X)\n",
    "```\n",
    "*Recuerde escalar los datos antes de entregárselos al modelo*\n",
    "\n",
    "> **j.1)** Visualice los *keypoint* para una mejor comprensión visual de lo que son los descriptores manuales en alguna imagen aleatoria.\n",
    "```python\n",
    "sample_image = X[sample_index]\n",
    "gray_sample_image = pre_process(sample_image)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray_sample_image, None)\n",
    "\"\"\"draw and plot\"\"\"\n",
    "img=cv2.drawKeypoints(gray_sample_image,kp,sample_image)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> Entrene una red neuronal densa (la misma que sigue a las capas convoluciones definidas en los modelos previos), compare el desempeño de la red con el modelo más básico (o de peor desempeño) y el modelo de mejor desempeño obtenido hasta este punto. Comente sobre el entrenamiento (error y tiempos de ejecución) y resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1htP1tUw_Jxj"
   },
   "source": [
    "> **k)** Elija una de las redes entrenadas en esta sección (preferentemente una con buen desempeño) y determine los pares de objetos (por ejemplo “camiones” con “autos”) que la red tiende a confundir. Conjeture el motivo de tal confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czVixvEg_SM9"
   },
   "source": [
    "> **l)** Elija una de las redes entrenadas (preferentemente una con buen desempeño) y visualice los pesos correspondientes a los filtros de la primera capa convolucional. Visualice además el efecto del filtro sobre algunas imágenes de entrenamiento. Repita el proceso para los pesos de la última capa convolucional; Comente y compare con los descriptores SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dL5iY0wswax"
   },
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 2. *Transfer Learning*\n",
    "\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/05/31130754/transfer-learning.jpeg\" , style=\"float: right;\" />\n",
    "\n",
    "En esta sección se trabajará con el dataset trabajado anteriormente, CIFAR [3], pero en su versión más fina, en el cual se presentan 100 tipos distintos de categorías a clasificar la imagen (mutuamente excluyente), no 10 como se usó en las actividades anteriores. La estructura es la misma, son 60000 imágenes RGB de 32 $\\times$ 32 píxeles separados en 50 mil de entrenamiento y 10 mil de pruebas.  \n",
    "Aquí se experimentará con el concepto de *transfer learning* el cual consta en transferir conocimiento de un dominio fuente (*source domain*) a un dominio objetivo (*target domain*). En redes neuronales existen muchas representaciones de esto, en común consta en pre inicializar los pesos de la red de alguna manera que no sea con distribuciones de manera aleatoria (*fine tunning*). También está lo que es utilizar una representación generada a través de otra red entrenada con muchos datos, esto es tomar la red y \"*congelar*\" sus primeras capas para tomar esta representación y no entrenar esos pesos, lo que realizaremos en esta sección. \n",
    "\n",
    "Para cargar los datos utilice el siguiente comando:\n",
    "```python\n",
    "from keras.datasets import cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "```\n",
    "\n",
    "Normalice entre [0,1] y transforme las etiquetas en *one hot vectors*.\n",
    "```python\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=100)\n",
    "x_train_norm = x_train/255.0\n",
    "x_test_norm = x_test/255.0\n",
    "```\n",
    "\n",
    "> a) Entrene una red neuronal convolucional como se presenta en el código a continuación durante 15 *epochs*, realizando un gráfico de evolución de la función de pérdida y de la exactitud del algoritmo (*accuracy*) sobre ambos conjuntos, entrenamiento y pruebas. Comente sobre el tiempo de ejecución de este entrenamiento. Reporte el *accuracy* del modelo final sobre el conjunto de pruebas.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train_norm.shape[1:],activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "...#add clasification layer\n",
    "model.summary()\n",
    "```\n",
    "<div class=\"alert alert-block alert-info\">Se utiliza una tasa de aprendizaje pequeña ya que es lo recomendable en *transfer learning*.</div>\n",
    ">```python\n",
    "optimizer_ = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, batch_size=128,epochs=15,verbose=1, validation_data=(x_test_norm,y_test)) #train it\n",
    "```\n",
    "\n",
    "> b) Debido al comportamiento de las curvas de entrenamiento, claramente se ve que se necesita un regularizador. Experimente utilizando Dropout con una tasa de 0.25 en las tandas convolucionales, elija donde situarlo, luego de la primera convolución, después de la segunda, solamente después del *pooling*, en todas o alguna forma que le parezca conveniente, de argumentos de ello. La idea es que se forme una idea de dónde conviene colocar el regularizador y porqué.\n",
    "\n",
    "> c) Una forma de hacer lo que se conoce como *transfer learning* es utilizar el conocimiento (los parámetros) aprendido por una red entrenada con millones de imágenes, y tomar estos parámetros como los pre entrenados. Para esto se utilizará el modelo VGG16 [7] proporcionado a través de la interfaz de *keras*. Visualice el modelo y sus 23 capas. Para esta instancia se utilizará todo lo aprendido por las capas convolucionales, es decir, se eliminan las capas densas del modelo y se agregan unas nuevas a ser entrenadas desde cero.  \n",
    "*Recuerde normalizar los datos de la manera en que fue entrenado VGG* ¿Cuál es éste proceso?\n",
    "```python\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "x_train_vgg = preprocess_input(x_train)\n",
    "x_test_vgg = preprocess_input(x_test)\n",
    "input_tensor=Input(shape=x_train_vgg.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor ) # LOAD PRETRAINED MODEL \n",
    "features_train = modelVGG.predict(x_train_vgg)\n",
    "features_test = modelVGG.predict(x_test_vgg)\n",
    "modelVGG.summary()\n",
    "```\n",
    "\n",
    "> d) Entrene esta red agregando una capa densa de 1024 neuronas seguido de un dropout de 0.5, finalmente es necesario agregar la capa de clasificación para las 100 clases. Utilice la misma configuración del optimizador para que las comparaciones sean válidas. Entrene unicamente por 10 *epochs* y grafique las curvas de entrenamiento con respecto al modelo definido en a) o con regularización definido en b) ¿Qué sucede? Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> e) Agregue una capa de normalización (*Batch Normalization* [8]) de las activaciones en las capas densas, esto es, restar por la media del batch y dividir por la desviación estándar. Vuelva a entrenar el modelo con la misma configuración pero ahora por **15 *epochs***. Comente lo observado y compare las curvas de convergencia con los modelos anteriores ¿Por qué esto mejora a lo presentado en e)? Realice los mismos gráficos que en a) a través del número de *epochs* y comente sobre el tiempo de ejecución de este entrenamiento.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "...#clasification\n",
    "```\n",
    "\n",
    "> f) Finalmente experimente con utilizar toda la red pre-entrenada, eliminando la capa de clasificación de mil neuronas de VGG reemplazandola por la capa de clasificación para su modelo (o con alguna capa extra si estima conveniente), dejando \"congelada\" toda la red para atrás, ésto quiere decir que utilizará la representación generada por la última capa (no de clasificación) de la red VGG, ésto es las capas densas, no la convolucional como en la parte c). Grafique las curvas de entrenamiento (función de pérdida/*loss*) , comparando con b) y e).\n",
    "```python\n",
    "input_tensor=Input(shape=x_train_vgg.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=True,input_tensor=input_tensor ) #LOAD PRETRAINED MODEL \n",
    "modelVGG.layers.pop() #delete last softmax layer\n",
    "modelVGG.summary()\n",
    "features_train = modelVGG.predict(x_train_vgg)\n",
    "features_test = modelVGG.predict(x_test_vgg)\n",
    "\"\"\"Add your network\"\"\"\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "... #add your classification layer\n",
    "\"\"\"train it! \"\"\"\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train,y_train,epochs=15,batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> g) ¿Cuándo podría ser útil y cuando no utilizar *transfer learning* o una red pre-entrenada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t7CRUJ9sweH"
   },
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 3. CNN sobre texto\n",
    "\n",
    "Cuando oimos sobre redes neuronales convolucionales (CNN) normalmente pensamos en visión artificial. Las CNN fueron responsables de los principales avances en la clasificación de imágenes y son el núcleo de la mayoría de los sistemas de *Computer Vision* en la actualidad, desde el etiquetado automático de fotos de Facebook hasta los autos que conducen por sí mismos.\n",
    "\n",
    "Más recientemente, también hemos empezado a aplicar CNN a problemas de procesamiento del lenguaje natural (NLP) y hemos obtenido resultados interesantes. Como sabemos, las redes convolucionales tienen importantes ventajas como invarianza a rotaciones y traslaciones así como la conectividad local (características de nivel inferior en una representación de nivel superior), además de lo que las hace fuertemente ventajosas, el **compartir** parámetros.\n",
    "\n",
    "\n",
    "**¿Cómo se aplica esto a NLP?**  \n",
    "En esta experimentación apicaremos una red CNN al dataset  __[Adzuna](https://www.kaggle.com/c/job-salary-prediction)__ que contiene cientos de miles de registros que en su mayoría corresponden a texto no estructurado versus sólo unos pocos estructurados. Los registros pueden estar en varios formatos diferentes debido a los cientos de diferentes fuentes de registros, los cuales corresponden a anuncios de empleadores en busca de trabajadores.  \n",
    "Es decir, cada fila es un anuncio que, en estricto rigor, representa una sentencia típicamente trabajada como vectores de word embeddings como **word2vec** o **GloVe**. Así, para una frase de 10 palabras bajo representaciones de *embeddings* utilizando 100 dimensiones tendríamos una matriz de 10 × 100 como entrada, lo que simularía nuestra \"imagen\".\n",
    "\n",
    "\n",
    "Su tarea es entonces, predecir el salario (valor continuo) de un determinado anuncio en base al texto indicado en éste. Igualmente puede valerse de otros atributos del anuncio como por ejemplo la ubicación, tipo de contrato, etc. \n",
    "\n",
    "\n",
    "A continuación se presenta un código de guía para leer los archivos y pre-procesarlos. Deberá añadir y realizar lo que estime conveniente.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizer (WordNetLemmatizer())\n",
    "#stemming?\n",
    "\n",
    "df=pd.read_csv(\"Train_rev1.csv\")\n",
    "df.head()\n",
    "\n",
    "def pre_procesar(df):\n",
    "    #preprocesar texto de los anuncios\n",
    "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
    "    for s in textos:\n",
    "        s= s.lower()\n",
    "        s= re.sub(r'[^\\w]', ' ',s)\n",
    "        s= re.sub(r'\\b[a-z]\\b', ' ',  s)\n",
    "        s= re.sub(r'\\b[a-z][a-z]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9][0-9]\\b', ' ',  s)\n",
    "        s= re.sub(r'[^\\w.]', ' ', s)\n",
    "        s= list(s.split())\n",
    "        #s= eliminación de stopwords\n",
    "        #s= stemming o lemmatization\n",
    "        #guardar texto procesado\n",
    "        \n",
    "    return df_procesado \n",
    "  ```\n",
    " \n",
    "```python\n",
    "y_dataframe=df['SalaryNormalized'].values\n",
    "x_dataframe=df[['FullDescription',...]]\n",
    "\n",
    "k=len(df_procesado)\n",
    "x_train=df_procesado[0:int(k*0.70)] #70% training\n",
    "x_val=df_procesado[int(k*0.70):int(k*0.85)] #15% validation\n",
    "x_test=df_procesado[int(k*0.85):] #15% test\n",
    "```\n",
    "\n",
    "### Embeddings \n",
    "\n",
    "En lugar de entrenar nuestros vectores embeddings utilizaremos el archivo __[Glove](https://www.kaggle.com/terenceliu4444/glove6b100dtxt#glove.6B.100d.txt)__ el cual cuenta con las representaciones vectoriales (de dimensionalidad 100) ya entrenadas sobre una amplia base de datos. Puede encontrar más detalle en https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "```python\n",
    "##armar diccionario word, index para posterior construccion de matriz de embeddings de glove\n",
    "word_index=dict()\n",
    "j=0\n",
    "for frase in x_train:\n",
    "    seq=frase.split()\n",
    "    for term in seq:\n",
    "        if term not in word_index.keys():\n",
    "            word_index[term]=j\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_vector=100\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words sin match en Glove, serán vectores de ceros.\n",
    "        embedding_matrix[i] = embedding_vector    \n",
    "        \n",
    "```\n",
    "### Modelo\n",
    "\n",
    "```python\n",
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "x_new_train = [[word_index[word] for word in text.split()] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text.split() if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 150 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool = MaxPooling1D(pool_size=)(cov1)\n",
    "...\n",
    "flat = Flatten()(layerK)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)\n",
    "```\n",
    "### Evaluación de predicciones\n",
    "Para las predicciones evalúe la métrica *Mean Absolute Error* (MAE)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE on train: \",mean_absolute_error(y_train, model.predict(Xtrain)))\n",
    "print(\"MAE on validation: \",mean_absolute_error(y_val, model.predict(Xval)))\n",
    "```\n",
    "\n",
    "> **Intente resolver el problema experimentando con las ayudas que se entregan en el código y lo aprendido hasta ahora en el curso. Se espera que llegue a un MAE menor a 7000 en el conjunto de pruebas. No olvide documentar todo lo experimentando en este Informe Jupyter así como el argumento de sus decisiones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tc927yi-WkfM"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#train_file = files.upload()\n",
    "#test_file = files.upload()\n",
    "#val_file = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "Wd9G5qa1AM0K",
    "outputId": "3a307c2a-812e-442e-e852-2f70423230a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/diego/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "stoplist = stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# lemmatizer (WordNetLemmatizer())\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"Train_rev1.csv\")\n",
    "#df_test = pd.read_csv(\"Test_rev1.csbv\")\n",
    "#df_val = pd.read_csv(\"Valid_rev1.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = df_train['SalaryNormalized'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Salaries Histogram')\n",
    "plt.hist(salaries, bins = 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpxIG6VKxVAm"
   },
   "outputs": [],
   "source": [
    "def pre_procesar(df):\n",
    "    #preprocesar texto de los anuncios\n",
    "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
    "    for column in ['FullDescription']:\n",
    "        df[column] = df[column].str.lower()\n",
    "        df[column] = df[column].str.replace(r'[^\\w]', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[a-z]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[a-z][a-z]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9][0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9][0-9][0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'[^\\w.]', ' ')\n",
    "        df[column] = df[column].str.split() # Split\n",
    "        df[column] = df[column].apply(lambda x: [item for item in x if item not in stoplist]) #Removiendo stopwords\n",
    "        df[column] = df[column].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "        df[column] = df[column].str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_procesar(df_train)\n",
    "#pre_procesar(df_test)\n",
    "#pre_procesar(df_val)\n",
    "\n",
    "df_procesado = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los datos procesados, ya que todo el procesamiento de texto hecho demora bastante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos\n",
    "df_procesado.to_csv('df_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer los datos\n",
    "df_procesado = pd.read_csv('df_procesado.csv')\n",
    "\n",
    "df_procesado['FullDescription'] = df_procesado['FullDescription'].str.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procesado['FullDescription']\n",
    "\n",
    "type(df_procesado['FullDescription'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que se nos dio poseia 3 archivos, el de entrenamiento, el de testeo, y el de validación. Sin embargo\n",
    "solo usaremos el de entrenamiento, debido a que es el único que tiene las etiquetas (\"SalaryNormalized\"), y separaremos el set de entreamiento en 3 partes, para tener un set de validacion y otro de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(9001)\n",
    "\n",
    "df_shuffle = df_procesado.sample(frac=1)\n",
    "df_shuffle.reset_index()\n",
    "k=len(df_shuffle)\n",
    "\n",
    "df_train = df_shuffle[0:int(k*0.70)] #70% training\n",
    "df_val = df_shuffle[int(k*0.70):int(k*0.85)] #15% validation\n",
    "df_test = df_shuffle[int(k*0.85):] #15% test\n",
    "\n",
    "y_train = df_train['SalaryNormalized'].values\n",
    "x_train = df_train['FullDescription']\n",
    "y_test = df_test['SalaryNormalized'].values\n",
    "x_test = df_test['FullDescription']\n",
    "y_val = df_val['SalaryNormalized'].values\n",
    "x_val = df_val['FullDescription']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras luego del procesamiento :  141107\n",
      "Se encontraron 400000 terminos con sus vectores de embedding.\n"
     ]
    }
   ],
   "source": [
    "##armar diccionario word, index para posterior construccion de matriz de embeddings de glove\n",
    "word_index=dict()\n",
    "j=0\n",
    "for frase in x_train:\n",
    "    for term in frase:\n",
    "        if term not in word_index.keys():\n",
    "            word_index[term]=j\n",
    "            j+=1\n",
    "print('Total de palabras luego del procesamiento : ',len(word_index))\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_vector=100\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words sin match en Glove, serán vectores de ceros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario\n",
    "\n",
    "Podemos ver que la cantidad de palabras detectadas es excesiva. Esto quiere decir que el preprocesamiento que se nos brindó no fue suficiente. Analizando las palabras hay muchas con simbolos que no son letras, o con palabras pegadas. Esto también se debe a que la data estaba bastante \"sucia\", con palabras no convencionales, y limpiarla será bastante dificil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "x_new_train = [[word_index[word] for word in text] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 150 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool1 = MaxPooling1D(pool_size=2)(cov1)\n",
    "drop1 = Dropout(0.25)(pool1)\n",
    "cov2= Conv1D(128, 5, activation='relu',padding='same')(drop1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(cov2)\n",
    "drop2 = Dropout(0.25)(pool2)\n",
    "flat = Flatten()(drop2)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171337 samples, validate on 36715 samples\n",
      "Epoch 1/25\n",
      "171337/171337 [==============================] - 323s 2ms/step - loss: 297086897.4196 - acc: 5.8365e-06 - val_loss: 226301067.3623 - val_acc: 5.4474e-05\n",
      "Epoch 2/25\n",
      "171337/171337 [==============================] - 324s 2ms/step - loss: 224049594.4954 - acc: 2.9182e-05 - val_loss: 214177968.1917 - val_acc: 2.7237e-05\n",
      "Epoch 3/25\n",
      "171337/171337 [==============================] - 320s 2ms/step - loss: 214355787.0970 - acc: 4.6692e-05 - val_loss: 211242260.2359 - val_acc: 5.4474e-05\n",
      "Epoch 4/25\n",
      "171337/171337 [==============================] - 325s 2ms/step - loss: 207246021.8203 - acc: 2.9182e-05 - val_loss: 211856969.9347 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "171337/171337 [==============================] - 309s 2ms/step - loss: 201848221.4420 - acc: 3.5019e-05 - val_loss: 197968510.7275 - val_acc: 2.7237e-05\n",
      "Epoch 6/25\n",
      "171337/171337 [==============================] - 308s 2ms/step - loss: 197616776.1896 - acc: 3.5019e-05 - val_loss: 205418718.1292 - val_acc: 2.7237e-05\n",
      "Epoch 7/25\n",
      "171337/171337 [==============================] - 306s 2ms/step - loss: 194509374.7496 - acc: 4.6692e-05 - val_loss: 195637153.8260 - val_acc: 2.7237e-05\n",
      "Epoch 8/25\n",
      "171337/171337 [==============================] - 306s 2ms/step - loss: 191177846.8808 - acc: 3.5019e-05 - val_loss: 216346094.0032 - val_acc: 2.7237e-05\n",
      "Epoch 9/25\n",
      " 23808/171337 [===>..........................] - ETA: 3:54 - loss: 180651537.7204 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40718ab2a655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que este modelo claramente no ha dado frutos. Se usaron dos capas convolucionales. El uso de solo una capa tampoco resulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 20, 100)           14110700  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 20, 128)           64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 641       \n",
      "=================================================================\n",
      "Total params: 14,257,517\n",
      "Trainable params: 146,817\n",
      "Non-trainable params: 14,110,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "x_new_train = [[word_index[word] for word in text] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 20 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool1 = MaxPooling1D(pool_size=2)(cov1)\n",
    "drop1 = Dropout(0.25)(pool1)\n",
    "cov2= Conv1D(128, 5, activation='relu',padding='same')(drop1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(cov2)\n",
    "drop2 = Dropout(0.25)(pool2)\n",
    "flat = Flatten()(drop2)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171337 samples, validate on 36715 samples\n",
      "Epoch 1/25\n",
      "171337/171337 [==============================] - 40s 231us/step - loss: 422894204.1161 - acc: 4.0855e-05 - val_loss: 298038527.0944 - val_acc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 286122517.9650 - acc: 2.9182e-05 - val_loss: 276168699.2743 - val_acc: 2.7237e-05\n",
      "Epoch 3/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 273168471.1947 - acc: 4.0855e-05 - val_loss: 270735950.3131 - val_acc: 5.4474e-05\n",
      "Epoch 4/25\n",
      "171337/171337 [==============================] - 46s 269us/step - loss: 265751127.8723 - acc: 4.0855e-05 - val_loss: 263846630.2623 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 260706862.6246 - acc: 4.6692e-05 - val_loss: 258898149.0809 - val_acc: 5.4474e-05\n",
      "Epoch 6/25\n",
      "171337/171337 [==============================] - 45s 261us/step - loss: 256566655.5096 - acc: 1.7509e-05 - val_loss: 252961412.4856 - val_acc: 2.7237e-05\n",
      "Epoch 7/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 253713355.0491 - acc: 2.3346e-05 - val_loss: 257329495.7344 - val_acc: 8.1710e-05\n",
      "Epoch 8/25\n",
      "171337/171337 [==============================] - 43s 250us/step - loss: 250945371.1067 - acc: 2.9182e-05 - val_loss: 247219976.2347 - val_acc: 0.0000e+00\n",
      "Epoch 9/25\n",
      "155136/171337 [==========================>...] - ETA: 3s - loss: 248834442.1650 - acc: 3.2230e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-40718ab2a655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que falla. Se observa que a un menor largo de input maximo, menor el tiempo de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Redes-Tarea2-Pregunta3.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
