{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47UiWbvtPMez"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/MARCA-Color.jpg\" title=\"Title text\" width=\"50%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 2 - Redes Convolucionales y sus aplicaciones </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "\n",
    "\n",
    "**Temas**  \n",
    "* Diseño y entrenamiento de Redes Neuronales Convolucionales (CNNs).\n",
    "* Regularización en Redes Convolucionales.\n",
    "* *Transfer Learning.*\n",
    "* Aplicaciones de las Redes Neuronales Convolucionales\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* **Fecha de entrega y discusión: 23 de Noviembre**\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<margarita.bugueno.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<cvalle@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea2-INF395-II-2018] \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Convolutional Neural Networks (CNN) en CIFAR.  \n",
    "[2.](#segundo) Transfer Learning.   \n",
    "[3.](#tercero) Convolutional Neural Network sobre texto.\n",
    "\n",
    "\n",
    "### **Nota Importante:**  \n",
    "Para esta actividad **si es que no se cuenta con GPU** se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__* . Así, podrá programar en la nube con recursos elevados y luego descargar el Jupyter Notebook y entregarlo en modo Informe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t7CRUJ9sweH"
   },
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 3. CNN sobre texto\n",
    "\n",
    "Cuando oimos sobre redes neuronales convolucionales (CNN) normalmente pensamos en visión artificial. Las CNN fueron responsables de los principales avances en la clasificación de imágenes y son el núcleo de la mayoría de los sistemas de *Computer Vision* en la actualidad, desde el etiquetado automático de fotos de Facebook hasta los autos que conducen por sí mismos.\n",
    "\n",
    "Más recientemente, también hemos empezado a aplicar CNN a problemas de procesamiento del lenguaje natural (NLP) y hemos obtenido resultados interesantes. Como sabemos, las redes convolucionales tienen importantes ventajas como invarianza a rotaciones y traslaciones así como la conectividad local (características de nivel inferior en una representación de nivel superior), además de lo que las hace fuertemente ventajosas, el **compartir** parámetros.\n",
    "\n",
    "\n",
    "**¿Cómo se aplica esto a NLP?**  \n",
    "En esta experimentación apicaremos una red CNN al dataset  __[Adzuna](https://www.kaggle.com/c/job-salary-prediction)__ que contiene cientos de miles de registros que en su mayoría corresponden a texto no estructurado versus sólo unos pocos estructurados. Los registros pueden estar en varios formatos diferentes debido a los cientos de diferentes fuentes de registros, los cuales corresponden a anuncios de empleadores en busca de trabajadores.  \n",
    "Es decir, cada fila es un anuncio que, en estricto rigor, representa una sentencia típicamente trabajada como vectores de word embeddings como **word2vec** o **GloVe**. Así, para una frase de 10 palabras bajo representaciones de *embeddings* utilizando 100 dimensiones tendríamos una matriz de 10 × 100 como entrada, lo que simularía nuestra \"imagen\".\n",
    "\n",
    "\n",
    "Su tarea es entonces, predecir el salario (valor continuo) de un determinado anuncio en base al texto indicado en éste. Igualmente puede valerse de otros atributos del anuncio como por ejemplo la ubicación, tipo de contrato, etc. \n",
    "\n",
    "\n",
    "A continuación se presenta un código de guía para leer los archivos y pre-procesarlos. Deberá añadir y realizar lo que estime conveniente.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizer (WordNetLemmatizer())\n",
    "#stemming?\n",
    "\n",
    "df=pd.read_csv(\"Train_rev1.csv\")\n",
    "df.head()\n",
    "\n",
    "def pre_procesar(df):\n",
    "    #preprocesar texto de los anuncios\n",
    "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
    "    for s in textos:\n",
    "        s= s.lower()\n",
    "        s= re.sub(r'[^\\w]', ' ',s)\n",
    "        s= re.sub(r'\\b[a-z]\\b', ' ',  s)\n",
    "        s= re.sub(r'\\b[a-z][a-z]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9][0-9]\\b', ' ',  s)\n",
    "        s= re.sub(r'[^\\w.]', ' ', s)\n",
    "        s= list(s.split())\n",
    "        #s= eliminación de stopwords\n",
    "        #s= stemming o lemmatization\n",
    "        #guardar texto procesado\n",
    "        \n",
    "    return df_procesado \n",
    "  ```\n",
    " \n",
    "```python\n",
    "y_dataframe=df['SalaryNormalized'].values\n",
    "x_dataframe=df[['FullDescription',...]]\n",
    "\n",
    "k=len(df_procesado)\n",
    "x_train=df_procesado[0:int(k*0.70)] #70% training\n",
    "x_val=df_procesado[int(k*0.70):int(k*0.85)] #15% validation\n",
    "x_test=df_procesado[int(k*0.85):] #15% test\n",
    "```\n",
    "\n",
    "### Embeddings \n",
    "\n",
    "En lugar de entrenar nuestros vectores embeddings utilizaremos el archivo __[Glove](https://www.kaggle.com/terenceliu4444/glove6b100dtxt#glove.6B.100d.txt)__ el cual cuenta con las representaciones vectoriales (de dimensionalidad 100) ya entrenadas sobre una amplia base de datos. Puede encontrar más detalle en https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "```python\n",
    "##armar diccionario word, index para posterior construccion de matriz de embeddings de glove\n",
    "word_index=dict()\n",
    "j=0\n",
    "for frase in x_train:\n",
    "    seq=frase.split()\n",
    "    for term in seq:\n",
    "        if term not in word_index.keys():\n",
    "            word_index[term]=j\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_vector=100\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words sin match en Glove, serán vectores de ceros.\n",
    "        embedding_matrix[i] = embedding_vector    \n",
    "        \n",
    "```\n",
    "### Modelo\n",
    "\n",
    "```python\n",
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "x_new_train = [[word_index[word] for word in text.split()] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text.split() if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 150 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool = MaxPooling1D(pool_size=)(cov1)\n",
    "...\n",
    "flat = Flatten()(layerK)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)\n",
    "```\n",
    "### Evaluación de predicciones\n",
    "Para las predicciones evalúe la métrica *Mean Absolute Error* (MAE)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE on train: \",mean_absolute_error(y_train, model.predict(Xtrain)))\n",
    "print(\"MAE on validation: \",mean_absolute_error(y_val, model.predict(Xval)))\n",
    "```\n",
    "\n",
    "> **Intente resolver el problema experimentando con las ayudas que se entregan en el código y lo aprendido hasta ahora en el curso. Se espera que llegue a un MAE menor a 7000 en el conjunto de pruebas. No olvide documentar todo lo experimentando en este Informe Jupyter así como el argumento de sus decisiones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tc927yi-WkfM"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#train_file = files.upload()\n",
    "#test_file = files.upload()\n",
    "#val_file = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "Wd9G5qa1AM0K",
    "outputId": "3a307c2a-812e-442e-e852-2f70423230a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/diego/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "stoplist = stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# lemmatizer (WordNetLemmatizer())\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"Train_rev1.csv\")\n",
    "#df_test = pd.read_csv(\"Test_rev1.csbv\")\n",
    "#df_val = pd.read_csv(\"Valid_rev1.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = df_train['SalaryNormalized'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.title('Salaries Histogram')\n",
    "plt.hist(salaries, bins = 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario\n",
    "\n",
    "Podemos observar que la distribución no es **normal**, y se parece bastante a una distribución **fisher**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "plt.title('Salaries Histogram')\n",
    "plt.hist(list(map(log, list(salaries))), bins = 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario\n",
    "\n",
    "Podemos ver que al aplicar logaritmo sobre el salario, parece seguir una distribución mas normal. Esto podría servir para que el entrenamiento sea mejor. De todas maneras primero intentaremos con el salario sin modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpxIG6VKxVAm"
   },
   "outputs": [],
   "source": [
    "def pre_procesar(df):\n",
    "    #preprocesar texto de los anuncios\n",
    "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
    "    for column in ['FullDescription']:\n",
    "        df[column] = df[column].str.lower()\n",
    "        df[column] = df[column].str.replace(r'[^\\w]', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[a-z]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[a-z][a-z]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9][0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'\\b[0-9][0-9][0-9]\\b', ' ')\n",
    "        df[column] = df[column].str.replace(r'[^\\w.]', ' ')\n",
    "        df[column] = df[column].str.split() # Split\n",
    "        df[column] = df[column].apply(lambda x: [item for item in x if item not in stoplist]) #Removiendo stopwords\n",
    "        df[column] = df[column].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "        df[column] = df[column].str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_procesar(df_train)\n",
    "#pre_procesar(df_test)\n",
    "#pre_procesar(df_val)\n",
    "\n",
    "df_procesado = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los datos procesados, ya que todo el procesamiento de texto hecho demora bastante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos\n",
    "df_procesado.to_csv('df_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer los datos\n",
    "df_procesado = pd.read_csv('df_procesado.csv')\n",
    "\n",
    "df_procesado['FullDescription'] = df_procesado['FullDescription'].str.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procesado['FullDescription']\n",
    "\n",
    "type(df_procesado['FullDescription'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que se nos dio poseia 3 archivos, el de entrenamiento, el de testeo, y el de validación. Sin embargo\n",
    "solo usaremos el de entrenamiento, debido a que es el único que tiene las etiquetas (\"SalaryNormalized\"), y separaremos el set de entreamiento en 3 partes, para tener un set de validacion y otro de test. \n",
    "\n",
    "Primero solo usaremos la columna **FullDescription** como eje X. Posteriormente se intentará agregar el título del trabajo, o incluso la ubicación, en caso de que no se logren resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(9001)\n",
    "\n",
    "df_shuffle = df_procesado.sample(frac=1)\n",
    "df_shuffle.reset_index()\n",
    "k=len(df_shuffle)\n",
    "\n",
    "df_train = df_shuffle[0:int(k*0.70)] #70% training\n",
    "df_val = df_shuffle[int(k*0.70):int(k*0.85)] #15% validation\n",
    "df_test = df_shuffle[int(k*0.85):] #15% test\n",
    "\n",
    "y_train = df_train['SalaryNormalized'].values\n",
    "x_train = df_train['FullDescription']\n",
    "y_test = df_test['SalaryNormalized'].values\n",
    "x_test = df_test['FullDescription']\n",
    "y_val = df_val['SalaryNormalized'].values\n",
    "x_val = df_val['FullDescription']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras luego del procesamiento :  141107\n",
      "Se encontraron 400000 terminos con sus vectores de embedding.\n"
     ]
    }
   ],
   "source": [
    "##armar diccionario word, index para posterior construccion de matriz de embeddings de glove\n",
    "word_index=dict()\n",
    "j=0\n",
    "for frase in x_train:\n",
    "    for term in frase:\n",
    "        if term not in word_index.keys():\n",
    "            word_index[term]=j\n",
    "            j+=1\n",
    "print('Total de palabras luego del procesamiento : ',len(word_index))\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_vector=100\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words sin match en Glove, serán vectores de ceros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario\n",
    "\n",
    "Podemos ver que la cantidad de palabras detectadas es excesiva. Esto quiere decir que el preprocesamiento que se nos brindó no fue suficiente. Analizando las palabras hay muchas con simbolos que no son letras, o con palabras pegadas. Esto también se debe a que la data estaba bastante \"sucia\", con palabras no convencionales, y limpiarla será bastante dificil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "x_new_train = [[word_index[word] for word in text] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 150 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool1 = MaxPooling1D(pool_size=2)(cov1)\n",
    "drop1 = Dropout(0.25)(pool1)\n",
    "cov2= Conv1D(128, 5, activation='relu',padding='same')(drop1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(cov2)\n",
    "drop2 = Dropout(0.25)(pool2)\n",
    "flat = Flatten()(drop2)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171337 samples, validate on 36715 samples\n",
      "Epoch 1/25\n",
      "171337/171337 [==============================] - 323s 2ms/step - loss: 297086897.4196 - acc: 5.8365e-06 - val_loss: 226301067.3623 - val_acc: 5.4474e-05\n",
      "Epoch 2/25\n",
      "171337/171337 [==============================] - 324s 2ms/step - loss: 224049594.4954 - acc: 2.9182e-05 - val_loss: 214177968.1917 - val_acc: 2.7237e-05\n",
      "Epoch 3/25\n",
      "171337/171337 [==============================] - 320s 2ms/step - loss: 214355787.0970 - acc: 4.6692e-05 - val_loss: 211242260.2359 - val_acc: 5.4474e-05\n",
      "Epoch 4/25\n",
      "171337/171337 [==============================] - 325s 2ms/step - loss: 207246021.8203 - acc: 2.9182e-05 - val_loss: 211856969.9347 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "171337/171337 [==============================] - 309s 2ms/step - loss: 201848221.4420 - acc: 3.5019e-05 - val_loss: 197968510.7275 - val_acc: 2.7237e-05\n",
      "Epoch 6/25\n",
      "171337/171337 [==============================] - 308s 2ms/step - loss: 197616776.1896 - acc: 3.5019e-05 - val_loss: 205418718.1292 - val_acc: 2.7237e-05\n",
      "Epoch 7/25\n",
      "171337/171337 [==============================] - 306s 2ms/step - loss: 194509374.7496 - acc: 4.6692e-05 - val_loss: 195637153.8260 - val_acc: 2.7237e-05\n",
      "Epoch 8/25\n",
      "171337/171337 [==============================] - 306s 2ms/step - loss: 191177846.8808 - acc: 3.5019e-05 - val_loss: 216346094.0032 - val_acc: 2.7237e-05\n",
      "Epoch 9/25\n",
      " 23808/171337 [===>..........................] - ETA: 3:54 - loss: 180651537.7204 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40718ab2a655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que este modelo claramente no ha dado frutos. Se usaron dos capas convolucionales. El uso de solo una capa tampoco resulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 20, 100)           14110700  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 20, 128)           64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 641       \n",
      "=================================================================\n",
      "Total params: 14,257,517\n",
      "Trainable params: 146,817\n",
      "Non-trainable params: 14,110,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "x_new_train = [[word_index[word] for word in text] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 20 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool1 = MaxPooling1D(pool_size=2)(cov1)\n",
    "drop1 = Dropout(0.25)(pool1)\n",
    "cov2= Conv1D(128, 5, activation='relu',padding='same')(drop1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(cov2)\n",
    "drop2 = Dropout(0.25)(pool2)\n",
    "flat = Flatten()(drop2)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171337 samples, validate on 36715 samples\n",
      "Epoch 1/25\n",
      "171337/171337 [==============================] - 40s 231us/step - loss: 422894204.1161 - acc: 4.0855e-05 - val_loss: 298038527.0944 - val_acc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 286122517.9650 - acc: 2.9182e-05 - val_loss: 276168699.2743 - val_acc: 2.7237e-05\n",
      "Epoch 3/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 273168471.1947 - acc: 4.0855e-05 - val_loss: 270735950.3131 - val_acc: 5.4474e-05\n",
      "Epoch 4/25\n",
      "171337/171337 [==============================] - 46s 269us/step - loss: 265751127.8723 - acc: 4.0855e-05 - val_loss: 263846630.2623 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 260706862.6246 - acc: 4.6692e-05 - val_loss: 258898149.0809 - val_acc: 5.4474e-05\n",
      "Epoch 6/25\n",
      "171337/171337 [==============================] - 45s 261us/step - loss: 256566655.5096 - acc: 1.7509e-05 - val_loss: 252961412.4856 - val_acc: 2.7237e-05\n",
      "Epoch 7/25\n",
      "171337/171337 [==============================] - 44s 255us/step - loss: 253713355.0491 - acc: 2.3346e-05 - val_loss: 257329495.7344 - val_acc: 8.1710e-05\n",
      "Epoch 8/25\n",
      "171337/171337 [==============================] - 43s 250us/step - loss: 250945371.1067 - acc: 2.9182e-05 - val_loss: 247219976.2347 - val_acc: 0.0000e+00\n",
      "Epoch 9/25\n",
      "155136/171337 [==========================>...] - ETA: 3s - loss: 248834442.1650 - acc: 3.2230e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-40718ab2a655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que falla. Se observa que a un menor largo de input maximo, menor el tiempo de cada epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Lamentablemente no se logró hacer un modelo predictivo que diera resultados que significaran algo. Los principales problemas uqe creemos que se tienen son el procesamiento de texto. Luego de procesar los datos, aplicando expresiones regulares, stemming y eliminación de stopwords se logró. Quizas algún problema en la confección de la entrada de la red (Vector embedding) también sea la causa de esto, y el poco tiempo que se tuvo para experimentar variando el tamaño de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Redes-Tarea2-Pregunta3.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
